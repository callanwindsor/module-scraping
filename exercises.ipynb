{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes for myself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Our jupyter/datascience-notebook Docker container comes with \n",
    "# BeautifulSoup4 and requests, both popular libraries!\n",
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "START_URL = 'https://brickset.com/sets/year-2016'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# page = requests.get(START_URL)\n",
    "\n",
    "# In order to work with web data, we’re going to want to access the text-based content of web files. \n",
    "# We can read the content of the server’s response with page.text \n",
    "# (or page.content if we would like to access the response in bytes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# page.text\n",
    "\n",
    "# In the next section, we can leverage the Beautiful Soup module to work with this textual data in a more \n",
    "# human-friendly manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# soup = BeautifulSoup(page.text, 'html.parser')\n",
    "\n",
    "# Doing thus gives us a parse tree from this parsed page that we’ll get from running Python’s \n",
    "# built-in html.parser over the HTML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(soup.prettify())\n",
    "\n",
    "# Shows one tag per line and the tags are nested b/c of the tree schema used by Beautiful Soup."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# titles = []\n",
    "# for i in range(0, len(chunk)):\n",
    "#     if i % 2 == 0:\n",
    "#         titles.append(soup.find_all('h1')[i].get_text())\n",
    "# print(titles) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metas = soup.findAll(\"div\",class_=\"meta\")\n",
    "# titles = []\n",
    "# for meta in metas:\n",
    "#     titles.append(meta.h1.text) \n",
    "# print(titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def get_titles(soup):  \n",
    "    \n",
    "    \"\"\" Returns a list of titles on the page \"\"\"\n",
    "    \n",
    "    metas = soup.findAll(\"div\",class_=\"meta\")\n",
    "    titles = []\n",
    "    for meta in metas:\n",
    "        titles.append(meta.h1.text) \n",
    "    return(titles)\n",
    "        \n",
    "    # the \"soup\" parameter is of the type that is\n",
    "    # returned by Beautiful Soup when it parses HTML.\n",
    "    # The function should then use the object to\n",
    "    # extract a list of titles (of the lego sets)\n",
    "    #\n",
    "    # Lookup the documentation for Beautiful Soup\n",
    "    # Figure out how to select the text of the title\n",
    "    # of each legoset. A title should look like: \n",
    "    # \"10252: Volkswagen Beetle\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_bricks(url):\n",
    "    \"\"\" Fetches Lego Bricks page and extracts titles \"\"\"\n",
    "    \n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.text, 'html.parser')\n",
    "    titles = get_titles(soup)\n",
    "    print(titles)\n",
    "    return titles\n",
    "    \n",
    "    # Lookup the documentation to the \"requests\" library\n",
    "    #\n",
    "    # Use requests to make a get request to the\n",
    "    # url given in the argument \"url\" (which is a string)\n",
    "    # and get the raw HTML body of the response\n",
    "    #\n",
    "    # Use \"BeautifulSoup\" to parse this HTML. \n",
    "    #\n",
    "    # Use the \"get_titles\" function to extract the\n",
    "    # titles from the BeautifulSoup object.\n",
    "    #\n",
    "    # Return the titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['10251:  Brick Bank', '10252:  Volkswagen Beetle', '10253:  Big Ben', '10254:  Winter Holiday Train', '10654:  XL Creative Brick Box', '10702:  Creative Building Set', '10705:  Creative Building Basket', '10720:  Police Helicopter Chase', '10721:  Iron Man vs. Loki', '10722:  Snake Showdown', \"10723:  Ariel's Dolphin Carriage\", '10724:  Batman & Superman vs. Lex Luthor', '10725:  Lost Temple', \"10726:  Stephanie's Horse Carriage\", \"10727:  Emma's Ice Cream Truck\", \"10728:  Mia's Vet Clinic\", \"10729:  Cinderella's Carriage\", '10801:  Baby Animals', '10802:  Savanna', '10803:  Arctic', '10804:  Jungle', '10805:  Around the World', '10806:  Horses', '10807:  Horse Trailer', '10808:  Little Plane']\n"
     ]
    }
   ],
   "source": [
    "bricks = parse_bricks(START_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "assert(bricks[0] == '10251:  Brick Bank')\n",
    "assert(bricks[9] == '10722:  Snake Showdown')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "name": "exercises.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
